% Copyright 2011-2015 David Hadka.  All Rights Reserved.
%
% This file is part of the MOEA Framework User Manual.
%
% Permission is granted to copy, distribute and/or modify this document under
% the terms of the GNU Free Documentation License, Version 1.3 or any later
% version published by the Free Software Foundation; with the Invariant Section
% being the section entitled "Preface", \cellcolor{red!25}No Front-Cover Texts, and \cellcolor{red!25}No Back-Cover
% Texts.  A copy of the license is included in the section entitled "GNU Free
% Documentation License".

\chapter{Optimization Algorithms}
\label{chpt:algorithms}

The MOEA Framework supports the 26 optimization algorithms listed in \tblref{tbl:algorithms}.  \tblref{tbl:algorithms} also indicates which of the decision variable representations from \chptref{chpt:representations} are supported by each algorithm.  The remainder of this chapter introduces each of these algorithms and details their use within the MOEA Framework.  Please refer to the literature cited with each algorithm for details.

\begin{sidewaystable}
  \centering
  \caption{List of available optimization algorithms.}
  \label{tbl:algorithms}
  \begin{tabular}{ll|cccccc|l}
  \hline
  Algorithm & Type & Real & Binary & Permutation & Grammar & Program & Constraints & Provider \\
  \hline
  AbYSS & Scatter Search & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  CellDE & Differential Evolution & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  DENSEA & Genetic Algorithm & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  ECEA & Genetic Algorithm & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & PISA \\
  eMOEA & $\epsilon$-Dominance & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & Native \\
  eNSGAII & $\epsilon$-Dominance & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & Native \\
  FastPGA & Genetic Algorithm & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  FEMO & Genetic Algorithm & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & PISA \\
  GDE3 & Differential Evolution & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & Native \\
  HypE & Indicator-Based & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & PISA \\
  IBEA & Indicator-Based & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  MOCell & Cellular & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  MOCHC & CHC Algorithm & \cellcolor{red!25}No & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  MOEAD & Decomposition & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & Native \\
  NSGAII & Genetic Algorithm & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & Native \\
  NSGAIII & Genetic Algorithm & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & Native \\
  OMOPSO & Particle Swarm & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  PAES & Evolutionary Strategy & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  PESA2 & Genetic Algorithm & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  Random & Random SEarch & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & Native \\
  SEMO2 & Genetic Algorithm & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & PISA \\
  SHV & Indicator-Based & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & PISA \\
  SIBEA & Indicator-Based & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & PISA \\
  SMPSO & Particle Swarm & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  SMSEMOA & Indicator-Based & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  SPAM & Indicator-Based & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & PISA \\
  SPEA2 & Genetic Algorithm & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{green!25}Yes & \cellcolor{red!25}No & \cellcolor{red!25}No & \cellcolor{green!25}Yes & JMetal \\
  \hline
  \end{tabular}
\end{sidewaystable}

\section{Native Algorithms}
The native algorithms listed in \tblref{tbl:algorithms} are implemented within the MOEA Framework, and thus support all functionality provided by the MOEA Framework.  This section details all of the native algorithms.

\subsection{$\epsilon$-MOEA}
$\epsilon$-MOEA is a steady-state MOEA that uses $\epsilon$-dominance archiving to record a diverse set of Pareto optimal solutions.  Full details of this algorithm are available in the following technical report:
\begin{quote}
Deb, K. et al. ``A Fast Multi-Objective Evolutionary Algorithm for Finding Well-Spread Pareto-Optimal Solutions.'' KanGAL Report No 2003002, Feb 2003. 
\end{quote}
Use the string \java{"eMOEA"} when creating instances of this algorithm with the \java{Executor}.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  epsilon & The $\epsilon$ values used by the $\epsilon$-dominance archive, which can either be a single value or a comma-separated array \\
  sbx.rate & The crossover rate for simulated binary crossover \\
  sbx.distributionIndex & The distribution index for simulated binary crossover \\
  pm.rate & The mutation rate for polynomial mutation \\
  pm.distributionIndex & The distribution index for polynomial mutation \\
  \hline
\end{tabularx}

\subsection{NSGA-II}
NSGA-II is one of the most widely used MOEAs and was introduced in the following paper:
\begin{quote}
Deb, K. et al.  ``A Fast Elitist Multi-Objective Genetic Algorithm: NSGA-II.''  IEEE Transactions on Evolutionary Computation, 6:182-197, 2000.
\end{quote}
Use the string \java{"NSGAII"} when creating instances of this algorithm with the \java{Executor}.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  sbx.rate & The crossover rate for simulated binary crossover \\
  sbx.distributionIndex & The distribution index for simulated binary crossover \\
  pm.rate & The mutation rate for polynomial mutation \\
  pm.distributionIndex & The distribution index for polynomial mutation \\
  \hline
\end{tabularx}

\subsection{NSGA-III}
NSGA-III is the many-objective successor to NSGA-II, using reference points to direct solutions towards a diverse set.  Full details are described in:
\begin{quote}
Deb, K. and Jain, H.  "An Evolutionary Many-Objective Optimization Algorithm Using Reference-Point-Based Nondominated Sorting Approach, Part I: Solving Problems With Box Constraints."  IEEE Transactions on Evolutionary Computation, 18(4):577-601, 2014.
\end{quote}
Use the string \java{"NSGAIII"} when creating instances of this algorithm with the \java{Executor}.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  divisions & The number of divisions \\
  sbx.rate & The crossover rate for simulated binary crossover \\
  sbx.distributionIndex & The distribution index for simulated binary crossover \\
  pm.rate & The mutation rate for polynomial mutation \\
  pm.distributionIndex & The distribution index for polynomial mutation \\
  \hline
\end{tabularx}

The \java{divisions} parameter governs the number of reference points, $H$, for an $M$ objective problem with the following equation:
\begin{equation}
  H = {M+divisions-1 \choose divisions}
\end{equation}
Deb and Jain also propose a two-layer approach for divisions for many-objective problems where an outer and inner division number is specified.  To use the two-layer approach, replace the \java{divisions} parameter with \java{divisionsOuter} and \java{divisionsInner}.

\subsection{$\epsilon$-NSGA-II}
$\epsilon$-NSGA-II is an extension of NSGA-II that uses an $\epsilon$-dominance archive and randomized restart to enhance search and find a diverse set of Pareto optimal solutions.  Full details of this algorithm are given in the following paper:
\begin{quote}
Kollat, J. B., and Reed, P. M. ``Comparison of Multi-Objective Evolutionary Algorithms for Long-Term Monitoring Design.''  Advances in Water Resources, 29(6):792-807, 2006.
\end{quote}
Use the string \java{"eNSGAII"} when creating instances of this algorithm with the \java{Executor}.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  epsilon & The $\epsilon$ values used by the $\epsilon$-dominance archive, which can either be a single value or a comma-separated array \\
  sbx.rate & The crossover rate for simulated binary crossover \\
  sbx.distributionIndex & The distribution index for simulated binary crossover \\
  pm.rate & The mutation rate for polynomial mutation \\
  pm.distributionIndex & The distribution index for polynomial mutation \\
  injectionRate & Controls the percentage of the population after a restart this is ``injected'', or copied, from the $\epsilon$-dominance archive \\
  windowSize & Frequency of checking if a randomized restart should be triggered (number of iterations) \\
  maxWindowSize & The maximum number of iterations between successive randomized restarts \\
  minimumPopulationSize & The smallest possible population size when injecting new solutions after a randomized restart \\
  maximumPopulationSize & The largest possible population size when injecting new solutions after a randomized restart \\
  \hline
\end{tabularx}

\subsection{MOEA/D}
MOEA/D is a relatively new optimization algorithm based on the concept of decomposing the problem into many single-objective formulations.  Two versions of MOEA/D exist in the literature.  The first, based on the paper cited below, is the original incarnation:
\begin{quote}
Li, H. and Zhang, Q.  ``Multiobjective Optimization problems with Complicated Pareto Sets, MOEA/D and NSGA-II.''  IEEE Transactions on Evolutionary Computation, 13(2):284-302, 2009.
\end{quote}
An extension to the original MOEA/D algorithm introduced a utility function that aimed to reduce the amount of ``wasted'' effort by the algorithm.  Full details of this extension are available in the following paper:
\begin{quote}
Zhang, Q., et al. ``The Performance of a New Version of MOEA/D on CEC09 Unconstrained MOP Test Instances.'' IEEE Congress on Evolutionary Computation, 2009. 
\end{quote}
Use the string \java{"MOEAD"} when creating instances of this algorithm with the \java{Executor}.  The parameters listed below are available.  Note that if the \texttt{updateUtility} parameter is NOT defined, then the original MOEA/D implementation is used.  If \texttt{updateUtility} is set, then the utility-based extension is enabled.
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  de.crossoverRate & The crossover rate for differential evolution \\
  de.stepSize & Control the size of each step taken by differential evolution \\
  pm.rate & The mutation rate for polynomial mutation \\
  pm.distributionIndex & The distribution index for polynomial mutation \\
  neighborhoodSize & The size of the neighborhood used for mating, given as a percentage of the population size \\
  delta & The probability of mating with an individual from the neighborhood versus the entire population \\
  eta & The maximum number of spots in the population that an offspring can replace, given as a percentage of the population size \\
  updateUtility & The frequency, in generations, at which utility values are updated \\
  \hline
\end{tabularx}

\subsection{GDE3}
GDE3 is the extension of differential evolution for multiobjective problems.  It was originally introduced in the following technical report:
\begin{quote}
Kukkonen and Lampinen (2005). ``GDE3: The Third Evolution Step of Generalized Differential Evolution.'' KanGAL Report Number 2005013. 
\end{quote}
Use the string \java{"GDE3"} when creating instances of this algorithm with the \java{Executor}.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  de.crossoverRate & The crossover rate for differential evolution \\
  de.stepSize & Control the size of each step taken by differential evolution \\
  \hline
\end{tabularx}

\subsection{Random Search}
The random search algorithm simply randomly generates new solutions uniformly throughout the search space.  It is not intended as an ``optimization algorithm'' \emph{per se}, but as a way to compare the performance of other MOEAs against random search.  If an optimization algorithm can not beat random search, then continued use of that optimization algorithm should be questioned.

Use the string \java{"Random"} when creating instances of this algorithm with the \java{Executor}.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & This parameter only has a use when parallelizing evaluations; it controls the number of solutions that are generated and evaluated in parallel \\
  epsilon & The $\epsilon$ values used by the $\epsilon$-dominance archive, which can either be a single value or a comma-separated array (this parameter is optional) \\
  \hline
\end{tabularx}

\section{JMetal Algorithms}
Many of the optimization algorithms that can be executed within the MOEA Framework are provided by the JMetal library.  JMetal supports only the real-valued, binary, and permutation encodings.  Each of the descriptions below will indicate which of these encodings, if any, the algorithm supports.  For each encoding, a different set of parameters are available.  For real-valued encodings, the additional parameters are:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  sbx.rate & The crossover rate for simulated binary crossover \\
  sbx.distributionIndex & The distribution index for simulated binary crossover \\
  pm.rate & The mutation rate for polynomial mutation \\
  pm.distributionIndex & The distribution index for polynomial mutation \\
  \hline
\end{tabularx}
\newline
\newline
For binary encodings, the additional parameters are:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  1x.rate & The crossover rate for single-point crossover \\
  bf.rate & The mutation rate for bit flip mutation \\
  \hline
\end{tabularx}
\newline
\newline
For permutation encodings, the additional parameters are:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  pmx.rate & The crossover rate for PMX crossover \\
  swap.rate & The mutation rate for the swap operator \\
  \hline
\end{tabularx}

\subsection{AbYSS}
AbYSS is a hybrid scatter search algorithm that uses genetic algorithm operators.  It was originally introduced in the following paper:
\begin{quote}
Nebro, A. J., et al.  ``AbYSS: Adapting Scatter Search to Multiobjective Optimization.''  IEEE Transactions on Evolutionary Computation, 12(4):349-457, 2008.
\end{quote}
Use the string \java{"AbYSS"} when creating instances of this algorithm with the \java{Executor}.  Only real-valued decision variables are supported.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  archiveSize & The size of the archive \\
  refSet1Size & The size of the first reference set \\
  refSet2Size & The size of the second reference set \\
  improvementRounds & The number of iterations that the local search operator is applied \\
  \hline
\end{tabularx}

\subsection{CellDE}
CellDE is a hybrid cellular genetic algorithm (meaning mating only occurs among neighbors) combined with differential evolution.  CellDE was introduced in the following study:
\begin{quote}
Durillo, J. J., et al.  ``Solving Three-Objective Optimization Problems Using a new Hybrid Cellular Genetic Algorithm.''  Parallel Problem Solving from Nature - PPSN X, Springer, 661-370, 2008.
\end{quote}
Use the string \java{"CellDE"} when creating instances of this algorithm with the \java{Executor}.  CellDE defines its own parameters for its real-valued operators as listed below:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  archiveSize & The size of the archive \\
  feedBack & Controls the number of solutions from the archive that are fed back into the population \\
  de.crossoverRate & The crossover rate for differential evolution \\
  de.stepSize & Control the size of each step taken by differential evolution \\
  \hline
\end{tabularx}

\subsection{DENSEA}
DENSEA is the duplicate elimination non-domination sorting evolutionary algorithm discussed in the following paper:
\begin{quote}
D. Greiner, et al.  ``Enhancing the multiobjective optimum design of structural trusses with evolutionary algorithms using DENSEA.''  44th AIAA (American Institute of Aeronautics and Astronautics) Aerospace Sciences Meeting and Exhibit, AIAA-2006-1474, 2006. 
\end{quote} 
Use the string \java{"DENSEA"} when creating instances of this algorithm with the \java{Executor}.  DENSEA supports real-valued, binary, and permutation encodings.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  \hline
\end{tabularx}

\subsection{FastPGA}
FastPGA is a genetic algorithm that uses adaptive population sizing to solve time-consumping problems more efficiencly.  It was introduced in the following paper:
\begin{quote}
Eskandari, H., et al.  ``FastPGA: A Dynamic Population Sizing Approach for Solving Expensive Multiobjective Optimization Problems.''  Evolutionary Multi-Criterion Optimization, Springer, 141-155, 2007.
\end{quote}
Use the string \java{"FastPGA"} when creating instances of this algorithm with the \java{Executor}.  FastPGA supports real-valued, binary, and permutation encodings.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  maxPopSize & The maximum size of the population \\
  initialPopulationSize & The initial size of the population \\
  a & Constant controlling the population size \\
  b & Multiplier controlling the population size \\
  c & Constant controlling the number of offspring \\
  d & Multiplier controlling the number of offspring \\
  termination & If 0, the algorithm terminates early if all solutions like on the Pareto optimal front \\
  \hline
\end{tabularx}

\subsection{IBEA}
IBEA is a indicator-based MOEA that uses the hypervolume performance indicator as a means to rank solutions.  IBEA was introduced in the following paper:
\begin{quote}
Zitzler, E. and K\"unzli, S.  ``Indicator-based selection in multiobjective search.'' In Parallel Problem Solving from Nature (PPSN VIII), Lecture Notes in Computer Science, pages 832–842, Berlin / Heidelberg, Springer, 2004.
\end{quote}
Use the string \java{"IBEA"} when creating instances of this algorithm with the \java{Executor}.  IBEA supports real-valued, binary, and permutation encodings.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  archiveSize & The size of the archive \\
  \hline
\end{tabularx}

\subsection{MOCell}
MOCell is the multiobjective version of a cellular genetic algorithm.  It was originally introduced at the following workshop:
\begin{quote}
Nebro, A. J., et al.  ``A Cellular Genetic Algorithm for Multiobjective Optimization.''  Proceedings of the Workshop on Nature Inspired Cooperative Strategies for Optimization, Granada, Spain, 25-36, 2006.
\end{quote}
Use the string \java{"MOCell"} when creating instances of this algorithm with the \java{Executor}.  MOCell supports real-valued, binary, and permutation encodings.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  archiveSize & The size of the archive \\
  feedBack & Controls the number of solutions from the archive that are fed back into the population \\
  \hline
\end{tabularx}

\subsection{MOCHC}
MOCHC is a genetic algorithm that combines a conservative selection strategy with highly disruptive recombination, which unlike traditional MOEAs aims to produce offspring that are maximally different from both parents.  It was introduced in the following conference proceedings:
\begin{quote}
Nebro, A. J., et al.  ``Optimal Antenna Placement using a New Multi-objective CHC Algorithm.''  Proceedings of the 9th Annual Conference on Genetic and Evolutionary Computation, London, England, 876-883, 2007.
\end{quote}
Use the string \java{"MOCHC"} when creating instances of this algorithm with the \java{Executor}.  MOCHC defines its own parameters for its search operators as listed below:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  initialConvergenceCount & The threshold (as a percent of the number of bits in the encoding) used to determine similarity between solutions \\
  preservedPopulation & The percentage of the population that does not undergo cataclysmic mutation  \\
  convergenceValue & The convergence threshold that determines when cataclysmic mutation is applied \\
  populationSize & The size of the population \\
  hux.rate & The crossover rate for the highly disruptive recombination operator \\
  bf.rate & The mutation rate for bit-flip mutation \\
  \hline
\end{tabularx}

\subsection{OMOPSO}
OMOPSO is a multiobjective particle swarm optimization algorithm that includes an $\epsilon$-dominance archive to discover a diverse set of Pareto optimal solutions.  OMOPSO was originally introduced at the following conference:
\begin{quote}
Sierra, M. R. and Coello Coello, C. A.  ``Improving PSO-based multi-objective optimization using crowding, mutation and $\epsilon$-dominance.'' Evolutionary Multi-Criterion Optimization, Berlin, Germany, 505-519, 2005.
\end{quote}
Use the string \java{"OMOPSO"} when creating instances of this algorithm with the \java{Executor}.  OMOPSO defines its own parameters for its search operators as listed below:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  archiveSize & The size of the archive \\
  mutationProbability & The mutation probability for uniform and non-uniform mutation \\
  perturbationIndex & Controls the shape of the distribution for uniform and non-uniform mutation \\
  epsilon & The $\epsilon$ values used by the $\epsilon$-dominance archive \\
  \hline
\end{tabularx}

\subsection{PAES}
PAES is a multiobjective version of evolution strategy.  PAES tends to underperform when compared to other MOEAs, but it is often used as a baseline algorithm for comparisons.  PAES was introduced in the following conference proceedings:
\begin{quote}
Knowles, J. and Corne, D.  ``The Pareto Archived Evolution Strategy: A New Baseline Algorithm for Multiobjective Optimization.''  Proceedings of the 1999 Congress on Evolutionary Computation, Piscataway, NJ, 98-105, 1999.
\end{quote}
Use the string \java{"PAES"} when creating instances of this algorithm with the \java{Executor}.  PAES supports real-valued, binary, and permutation encodings.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  archiveSize & The size of the archive \\
  bisections & The number of bisections in the adaptive grid archive \\
  \hline
\end{tabularx}

\subsection{PESA-II}
PESA-II is another multiobjective evolutionary algorithm that tends to underperform other MOEAs but is often used as a baseline algorithm.  PESA-II was introduced in the following paper:
\begin{quote}
Corne, D. W., et al.  ``PESA-II: Region-based Selection in Evolutionary Multiobjective Optimization.''  Proceedings of the Genetic and Evolutionary Computation Conference, 283-290, 2001.
\end{quote}
Use the string \java{"PESA2"} when creating instances of this algorithm with the \java{Executor}.  PESA-II supports real-valued, binary, and permutation encodings.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  archiveSize & The size of the archive \\
  bisections & The number of bisections in the adaptive grid archive \\
  \hline
\end{tabularx}

\subsection{SMPSO}
SMPSO is a multiobjective particle swarm optimization algorithm that was originally presented at the following conference:
\begin{quote}
Nebro, A. J., et al.  ``SMPSO: A New PSO-based Metaheuristic for Multi-objective Optimization.''  2009 IEEE Symposium on Computational Intelligence in Multicriteria Decision-Making, 66-73, 2009.
\end{quote}
Use the string \java{"SMPSO"} when creating instances of this algorithm with the \java{Executor}.  SMPSO defines its own parameters for its operators as listed below:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  archiveSize & The size of the archive \\
  pm.rate & The mutation rate for polynomial mutation \\
  pm.distributionIndex & The distribution index for polynomial mutation \\
  \hline
\end{tabularx}

\subsection{SMSEMOA}
SMSEMOA is an indicator-based MOEA that uses the volume of the dominated hypervolume to rank individuals.  SMSEMOA is discussed in detail in the following paper:
\begin{quote}
Beume, N., et al.  ``SMS-EMOA: Multiobjective selection based on dominated hypervolume.''  European Journal of Operational Research, 181(3):1653-1669, 2007.
\end{quote}
Use the string \java{"SMSEMOA"} when creating instances of this algorithm with the \java{Executor}.  SMSEMOA supports real-valued, binary, and permutation encodings.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  offset & - \\
  \hline
\end{tabularx}

\subsection{SPEA2}
SPEA2 is an older but popular benchmark MOEA that uses the so-called ``strength-based'' method for ranking solutions.  SPEA2 was introduced in the following conference proceedings:
\begin{quote}
Zitzler, E., et al.  ``SPEA2: Improving the Strength Pareto Evolutionary Algorithm For Multiobjective Optimization. CIMNE, Barcelona, Spain, 2002.
\end{quote}
Use the string \java{"SPEA2"} when creating instances of this algorithm with the \java{Executor}.  SPEA2 supports real-valued, binary, and permutation encodings.  The following parameters are available:
\newline
\newline
\begin{tabularx}{\linewidth}{lX}
  \hline
  Parameter & Description \\
  \hline
  populationSize & The size of the population \\
  archiveSize & The size of the archive \\
  \hline
\end{tabularx}

\section{PISA Algorithms}
The MOEA Framework has been extensively tested with the PISA algorithms listed in \tblref{tbl:algorithms}.  PISA algorithms are provided by a third-party and are not distributed by the MOEA Framework, but the MOEA Framework can be configured to run such optimization algorithms.  This section describes how to connect the MOEA Framework to a PISA algorithm.

The Platform and Programming Language Independent Interface for Search Algorithms (PISA), available at \webpage{http://www.tik.ee.ethz.ch/pisa/}, is a language-neutral programming interface for creating search and optimization algorithms.  PISA specifies three components required for search algorithms:

\begin{enumerate}
  \item selectors, which define the optimization algorithms;
  \item variators, which define the optimization problems; and
  \item a communication scheme using plaintext files.
\end{enumerate}

This design offers several benefits.  First, it clearly demarcates the responsibilities of algorithm experts from those of application engineers.  The algorithm experts focus on designing and improving the behavior of optimization algorithms (i.e., selectors), whereas application engineers are responsible for encoding the details of their problem (i.e., variators).  Second, the file-based communication scheme employed by PISA permits selectors and variators to be written in nearly any programming language, which may be paired with a selector/variator written in a completely different language.  Third, the standardized communication scheme enables plug-and-play integration, allowing one module to be swapped out for another with little to no effort.  For instance, one selector may be replaced by another simply by changing which executable is run.

The fundamental drawback of PISA is a result of its reliance on a file-based communication scheme.  File access on modern computers remains a (relatively) slow operation, which is further exacerbated by the need to constantly poll the communication files for changes.  Nonetheless, PISA opens the door to a number of optimization algorithms, including:

\begin{enumerate}
  \item Set Preference Algorithm for Multiobjective Optimization (SPAM)
  \item Sampling-Based Hypervolume-Oriented Algorithm (SHV)
  \item Simple Indicator-Based Evolutionary Algorithm (SIBEA)
  \item Hypervolume Estimation Algorithm for Multiobjective Optimization (HypE)
  \item Simple Evolutionary Multiobjective Optimizer (SEMO2)
  \item Fair Evolutionary Multiobjective Optimizer (FEMO)
  \item Epsilon-Constraint Evolutionary Algorithm (ECEA)
  \item Multiple Single Objective Pareto Sampling (MSOPS)
\end{enumerate}

For this reason, the MOEA Framework provides the support necessary to integrate with the PISA library.  The \class{PISAAlgorithm} class acts as a variator, which knows how to communicate with a PISA selector using the file-based communication protocol.

\subsection{Adding a PISA Selector}
A standardized method for adding PISA selectors to the MOEA Framework is provided.  The steps required to add a new PISA selector are:

\begin{enumerate}
  \item Download and extract a PISA selector
  \item Edit \file{global.properties}
    \begin{enumerate}
      \item Add the name of the selector, \plaintext{NAME}, to the comma-separated list of available PISA selectors in \plaintext{org.moeaframework.algorithm.pisa.algorithms}
      \item Add the property \plaintext{org.moeaframework.algorithm.pisa.NAME.command}, which points to the program executable which starts the PISA selector
      \item Provide a list of parameters, in the order required by the PISA selector, with the property \plaintext{org.moeaframework.algorithm.pisa.NAME.parameters}
      \item For each of the listed parameters, PARAM, add the property \plaintext{org.moeaframework.algorithm.pisa.NAME.PARAM} to set the default value for the parameter.  It is not necessary to list the seed parameter
    \end{enumerate}
\end{enumerate}

For example, if we install the HypE selector, we would first download the HypE binaries from \webpage{http://www.tik.ee.ethz.ch/pisa/}.  These binaries are typically packaged as a compressed file (.zip or .tar.gz).  Next, extract the contents of this compressed file into the MOEA Framework installation folder.  In this example, we extracted the contents to the folder \folder{pisa/HypE}.  Finally, add the following lines to the \file{global.properties} file:

\begin{lstlisting}[language=Plaintext]
org.moeaframework.algorithm.pisa.algorithms=HypE
org.moeaframework.algorithm.pisa.HypE.command = ./pisa/hype_win/hype.exe
org.moeaframework.algorithm.pisa.HypE.parameters = seed, tournament, mating, bound, nrOfSamples
org.moeaframework.algorithm.pisa.HypE.parameter.tournament = 5
org.moeaframework.algorithm.pisa.HypE.parameter.mating = 1
org.moeaframework.algorithm.pisa.HypE.parameter.bound = 2000
org.moeaframework.algorithm.pisa.HypE.parameter.nrOfSamples = -1
\end{lstlisting}

Once completed, you should be able to run the diagnostic tool and confirm that HypE appears in the list of available algorithms.  Additionally, HypE may be referenced throughout the MOEA Framework wherever the algorithm is specified as a string, such as:

\begin{lstlisting}[language=Java]
new Executor()
		.withProblem("Kursawe")
		.withAlgorithm("HypE")
		.withMaxEvaluations(10000)
		.withProperty("bound", 1000)
		.withProperty("tournament", 2)
		.run();
\end{lstlisting}

\subsection{Troubleshooting}

\noindent
\textit{I'm attempting to run the PISA algorithm, but nothing is happening.  The task manager shows the PISA executable is running, but shows 0\% CPU usage.}

\begin{quote}
The MOEA Framework uses your system's default temporary directory as the location of the files used to communicate with the PISA selector.  Some PISA selectors do not support paths containing spaces, and the path to the default temporary directory on older versions of Windows contains spaces.  This causes a miscommunication between the MOEA Framework and PISA, which generally causes the MOEA Framework and PISA executables to stall.

The easiest workaround is to override the temporary directory location so that the space is removed.  This can be accomplished by editing the \file{global.properties} file and adding the line:

\begin{lstlisting}[language=Plaintext]
java.io.tmpdir = C:/temp/
\end{lstlisting}
\end{quote}

\noindent
\textit{PISA runs fine for a while, but eventually crashes with the message ``Assertion failed: fp != null''.}

\begin{quote}
Some antivirus software is known to interfere with the file-based communication protocol used by PISA.  Antivirus programs which actively monitor files for changes may lock the file during a scan, potentially blocking access by the PISA selector.  Most PISA selectors will crash with the obscure message ``Assertion failed: fp != null''.

To verify this as the cause, you may temporarily disable your antivirus software and re-run the program.  Once verified, a permanent solution involves adding an exception to the antivirus software to prevent scanning the PISA communication files.  To implement this solution, first define the location of temporary files by adding the following line to the global.properties file:

\begin{lstlisting}[language=Plaintext]
java.io.tmpdir = C:/temp/
\end{lstlisting}

Then add an exception to your antivirus software to disable scanning files located in this directory.

(Note: Disabling an antivirus program from scanning a folder will leave its contents unprotected.  Follow these steps at your own risk.)
\end{quote}

\section{Borg MOEA}

The Borg MOEA is a state-of-the-art MOEA built with auto-adaptive multioperator search, $\epsilon$-progress to monitor search progress, and randomized restarts triggered by a lack of $\epsilon$-progress.  These features enable the Borg MOEA to solve challenging, real-world problems that cause other MOEAs to fail.  The Borg MOEA was first introduced in the following paper:
\begin{quote}
Hadka, D. and P. Reed (2013). ``Borg: An Auto-Adaptive Many-Objective Evolutionary Computing Framework.'' Evolutionary Computation, 21(2):231-259.
\end{quote}
Since the Borg MOEA is restricted to non-commercial and academic users, the Borg MOEA is not distributed with the MOEA Framework.  However, version 1.8 of the Borg MOEA includes a plugin for the MOEA Framework, allowing it to be called from within the MOEA Framework like any other optimization algorithm.  See the user manual accompanying the Borg MOEA for further details.  The Borg MOEA can be downloaded from \url{http://borgmoea.org/}.  Commercial users should visit \url{http://decisionvis.com} to license the Borg MOEA for use with commercial applications.

\section{Conclusion}
This chapter provided an overview of the optimization algorithms that are known to work with and extensively tested within the MOEA Framework.  By following the parameterization guidance provided in this chapter and the information in \tblref{tbl:algorithms}, you can apply any of these algorithms to solve your optimization problems.